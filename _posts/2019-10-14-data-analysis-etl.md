---
layout:     post
title:      "数据分析学习（二）"
subtitle:   " \"ETL\""
date:       2019-10-14 05:00:00
author:     "Jht"
header-img: "img/post-bg-data-analysis.jpg"
catalog: true
tags:
    - analysis
---

## ETL是个啥

ETL是Extraction-Transformation-Loading的缩写，中文名称为数据抽取、转换和加载到数据仓库。
目的是将企业中的分散、零乱、标准不统一的数据整合到一起，为企业的决策提供分析依据。

ETL与`数据分析六步曲`的对应关系：

- 数据收集
- 数据处理

![](/img/in-post/analysis/etl.jpg)

### ODS(Operational Data Store)

ODS是对源数据进行历史存档，保留源系统的所有历史数据
ODS层的作用：

- 全量的存储源数据
  - 源数据结构是怎样的，ODS数据库的结构就是怎样的。
  - 只做逻辑删除
- 支持下游系统的实时查询服务


### DW(Data Warehouse)

数据仓库，是一个面向主题的、集成的、相对稳定的（不可修改的）、反映历史变化的（随时间变化的），用于支撑管理决策的数据集合。数据仓库是一种特殊的数据库。

### DM(Data Mart)

它是面向主题组织数据的，从数据粒度来讲，它是轻度汇总级别的数据，已经不存在明细的数据了，从广度来说，它包含了所有业务数量。从分析角度讲，大概就是近几年。

我的理解：DM层根据业务需求把DW层数据进行聚合或生成宽表。

## 抽取渠道

渠道很多：

- 市场调研
- 爬虫
- 日志
- 数据库
- 服务器监控数据

我们拿日志举例来讲一下。

### 日志抽取

一般要对数据源进行持久化备份。方便日后进行数据恢复。

#### 数据源

- 用户访问日志
- 自定义事件日志
- 服务器监控日志
- 各服务产生的日志
- 操作系统日志
- 其他日志

#### 抽取频率

根据你的需求进行设置，可以是60秒，可以是1小时，可以是一小时。要考虑数据量，最好有限速机制，当数据量大的时候，根据相应的策略进行传输，来减少对系统的压力。


## 数据处理

数据分为：

- 符合要求的数据
- 不符合要求的数据

数据处理包括：

- 数据清洗
- 数据转换
  
### 数据清洗

不符合要求的数据
  
- 不完整的数据
  - 过滤掉，写入数据存储，待补充 
- 错误的数据
  - 空值处理
    - 设成默认值
    - 补充
      - 比如生日从身份号中提取
      - 比如从其他字段中计算 
    - 日期格式
    - 字段编码
    - 去除空格
    - 分列
      - 例如：北京海淀区分成`省`和`区`
    - 合并
    - 替换
      - 把同义词转成默认值
- 重复的数据
  - 有的时候处理完了，才能知道是否是重复数据，例：`北京`和`北 京`


### 数据转换

根据转化规则，对清洗过的数据进行转换

- 颗粒度转化，原始数据颗粒度比较细，有可能分析时，用不到，这就需要根据业务，对数据进行转化。
- 指标计算，有的指标不是简单的计算就能完成的，这就需要将这些数据计算好，存储起来


